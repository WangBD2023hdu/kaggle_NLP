{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\同步文件夹\\BaiduSyncdisk\\验证代码\\kaggle_NLP_competition\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142.85714285714286"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(130 + 110 + 140 + 150 + 80 + 110 + 130 + 150)/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WORKING_PATH = \"./text\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_set=dict()\n",
    "    train_set = []\n",
    "    val_set = []\n",
    "    test_set = []\n",
    "    for dataset in [\"train\"]:\n",
    "        file=open(os.path.join(WORKING_PATH,\"dataset_text/text_data/\",dataset+\".txt\"),\"rb\")\n",
    "        for line in file:\n",
    "            content=eval(line)\n",
    "            image=content[0]\n",
    "            sentence=content[1]\n",
    "            group=content[2]\n",
    "            if os.path.isfile(os.path.join(WORKING_PATH,\"dataset_image\",image+\".jpg\")):\n",
    "                train_set.append([content[0],content[1],content[2]])\n",
    "    for dataset in [\"valid\"]:\n",
    "        file=open(os.path.join(WORKING_PATH,\"dataset_text/text_data/\",dataset+\".txt\"),\"rb\")\n",
    "        for line in file:\n",
    "            content=eval(line)\n",
    "            image=content[0]\n",
    "            sentence=content[1]\n",
    "            group=content[3] #2 hashtag\n",
    "            if os.path.isfile(os.path.join(WORKING_PATH,\"dataset_image\",image+\".jpg\")):\n",
    "                val_set.append([content[0],content[1],content[3],content[2]])\n",
    "    for dataset in [\"test\"]:\n",
    "        file=open(os.path.join(WORKING_PATH,\"dataset_text/text_data/\",dataset+\".txt\"),\"rb\")\n",
    "        for line in file:\n",
    "            content=eval(line)\n",
    "            image=content[0]\n",
    "            sentence=content[1]\n",
    "            group=content[3] #2 is the \n",
    "            if os.path.isfile(os.path.join(WORKING_PATH,\"dataset_image\",image+\".jpg\")):\n",
    "                test_set.append([content[0],content[1],content[3],content[2]])\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def read_json(path):\n",
    "    with open(path,\"r\",encoding = 'utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def write_json(path,data):\n",
    "    with open(path,\"w\",encoding = 'utf-8') as f:\n",
    "        json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import os\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(dataset):\n",
    "    dataset_ = []\n",
    "    for sample in dataset:\n",
    "        line = sample[1].strip()\n",
    "        if \"sarcasm\" in line:\n",
    "            continue\n",
    "        if \"sarcastic\" in line:\n",
    "            continue\n",
    "        if \"reposting\" in line:\n",
    "            continue\n",
    "        if \"<url>\" in line:\n",
    "            continue\n",
    "        if \"joke\" in line:\n",
    "            continue\n",
    "        if \"humour\" in line:\n",
    "            continue\n",
    "        if \"humor\" in line:\n",
    "            continue\n",
    "        if \"jokes\" in line:\n",
    "            continue\n",
    "        if \"irony\" in line:\n",
    "            continue\n",
    "        if \"ironic\" in line:\n",
    "            continue\n",
    "        if \"exgag\" in line:\n",
    "            continue\n",
    "        sample[1] = line\n",
    "        dataset_.append(sample)\n",
    "    return dataset_\n",
    "\n",
    "trainset = clean(train_set)\n",
    "valset = clean(val_set)\n",
    "testset = clean(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final paths\n",
    "write_json(\"./sarcasm/twitter/dataset_text/train.json\", trainset)\n",
    "write_json(\"./sarcasm/twitter/dataset_text/val.json\", valset)\n",
    "write_json(\"./sarcasm/twitter/dataset_text/test.json\", testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization for twitter-image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i= random.randint(1,2000)\n",
    "# print(423)\n",
    "i=1604 \n",
    "print(val[i][1])\n",
    "print(val[i][2],val[i][3])\n",
    "print(val[i][-3])\n",
    "display_img(test[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "def display_img(flag):\n",
    "    path = \"./sarcasm/twitter/dataset_image\"\n",
    "    path = os.path.join(path,flag+\".jpg\")\n",
    "    im=Image.open(path)\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set),len(val_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[423]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_switch = Image.open(\"./sarcasm/demo.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_switch = img_switch.resize((224,224)).convert('RGBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.paste(img_switch,(0,0,224,224),mask=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, g, b, a = img_switch.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Image.new('RGB', (224, 224), (0,0,0)).convert('RGBA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = img_switch.size[0]               #获取图片宽度\n",
    "h = img_switch.size[1]               #获取图片高度\n",
    "img_1 = img_switch.crop([2*w/3, 2*h/3, w, h])       #获取左上1/4的图片\n",
    "img_1.save('demo_images/' + '8' + '.png')          #保存在本地图片命名为1.jpg\n",
    "# img_2 = img.crop([w/2, 0, w, h/2])       #获得右上1/4的图片\n",
    "# img_2.save('./' + '2' + '.jpg')          #保存在本地图片命名为2.jpg\n",
    "# img_3 = img.crop([0, h/2, w/2, h])       #获取左下1/4的图片\n",
    "# img_3.save('./' + '3' + '.jpg')          #保存在本地图片命名为3.jpg\n",
    "# img_4 = img.crop([w/2, h/2, w, h])       #获取右下1/4的图片\n",
    "# img_4.save('./' + '4' + '.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=img_switch .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变图片被背景色\n",
    "b=img_switch .load()\n",
    "for y in range(224):\n",
    "    for x in range(224):\n",
    "        if all(b[x,y][i]>220 for i in range(4)):\n",
    "            b[x,y] = 238,233,233\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_switch.save(\"demo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 224 7*7 32*32\n",
    "# use pre_trained model B_32 L_32 \n",
    "model_name = 'B_32_imagenet1k'\n",
    "model = ViT(model_name, pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def B_32_embedding(dataset, img_path):\n",
    "    model_name = 'B_32'\n",
    "    model = ViT(model_name, pretrained=True)\n",
    "    tfms = transforms.Compose([transforms.Resize(model.image_size), transforms.ToTensor(), \n",
    "                               transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),])\n",
    "    print(model.image_size)\n",
    "    embedding = []\n",
    "    model.__delattr__(\"fc\")\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    for sample in dataset:\n",
    "        img = os.path.join(img_path,sample[0]+\".jpg\")\n",
    "        img = Image.open(img)\n",
    "        img = tfms(img).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            # remove class token\n",
    "            img = model(img.cuda())[0,:-1,:]\n",
    "        embedding.append(img.cpu())\n",
    "    return embedding\n",
    "\n",
    "def L_32_embedding(dataset, img_path):\n",
    "    model_name = 'L_32'\n",
    "    model = ViT(model_name, pretrained=True)\n",
    "    tfms = transforms.Compose([transforms.Resize(model.image_size), transforms.ToTensor(), \n",
    "                               transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),])\n",
    "    print(model.image_size)\n",
    "    embedding = []\n",
    "    model.__delattr__(\"fc\")\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    for sample in dataset:\n",
    "        img = os.path.join(img_path,sample[0]+\".jpg\")\n",
    "        img = Image.open(img)\n",
    "        img = tfms(img).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            # remove class token\n",
    "            img = model(img.cuda())[0,:-1,:]\n",
    "        embedding.append(img.cpu())\n",
    "    return embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_train_emb = B_32_embedding(trainset, img_path = \"./sarcasm/twitter/dataset_image\")\n",
    "B_val_emb = B_32_embedding(valset, img_path = \"./sarcasm/twitter/dataset_image\")\n",
    "B_test_emb = B_32_embedding(testset, img_path = \"./sarcasm/twitter/dataset_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_emb = L_32_embedding(trainset, img_path = \"./sarcasm/twitter/dataset_image\")\n",
    "L_val_emb = L_32_embedding(valset, img_path = \"./sarcasm/twitter/dataset_image\")\n",
    "L_test_emb = L_32_embedding(testset, img_path = \"./sarcasm/twitter/dataset_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(L_train_emb, \"./sarcasm/twitter/img_emb/train_L32.pt\")\n",
    "torch.save(L_val_emb, \"./sarcasm/twitter/img_emb/val_L32.pt\")\n",
    "torch.save(L_test_emb, \"./sarcasm/twitter/img_emb/test_L32.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\cmcr\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\cmcr\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet152 = models.resnet152(pretrained=True, progress = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Resnet152_embedding(dataset, img_path):\n",
    "    resnet152 = models.resnet152(pretrained=True, progress = True)\n",
    "    tfms = transforms.Compose([transforms.Resize((448,448)), transforms.ToTensor(), \n",
    "                               transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    w=int(224/7)\n",
    "    h=int(224/7)\n",
    "\n",
    "    embedding = []\n",
    "    resnet152.fc = torch.nn.Identity()\n",
    "    resnet152.cuda()\n",
    "    resnet152.eval()\n",
    "    for sample in dataset:\n",
    "        img = os.path.join(img_path,sample[0]+\".jpg\")\n",
    "        img = Image.open(img)\n",
    "        img = tfms(img).unsqueeze(0)\n",
    "        patch = []\n",
    "        for row in range(14):\n",
    "            for col in range(14):\n",
    "                patch.append(img[:,:,row*w:row*w+w,col*h:col*h+h])\n",
    "        patches = torch.cat(patch, dim=0)\n",
    "        with torch.no_grad():\n",
    "            embedding.append(resnet152(patches.cuda()).cpu())\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res152 = Resnet152_embedding(trainset,img_path='./twitter/dataset_image' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_res152,\"./twitter/img_emb/train_152.pt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_res152 = Resnet152_embedding(valset,img_path='./twitter/dataset_image' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_res152,\"./twitter/img_emb/val_152.pt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res152 = Resnet152_embedding(testset,img_path='./twitter/dataset_image' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_res152,\"./twitter/img_emb/test_152.pt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11111111111111111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 依赖生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_organize_caption(tokens,noun_phrases):\n",
    "    # tokens_smaple token+np\n",
    "    # token_map token_map[a] a 是\n",
    "    tokens_sample = []\n",
    "    chunk_index = 0\n",
    "    chunk_len = len(noun_phrases)\n",
    "    i = 0\n",
    "    token_map = []\n",
    "    while (i<len(tokens)):\n",
    "        if chunk_index<chunk_len:\n",
    "            if i<noun_phrases[chunk_index][1]:\n",
    "                tokens_sample.append(tokens[i][0])\n",
    "                token_map.append(len(tokens_sample)-1)\n",
    "                i = i+1\n",
    "            else:\n",
    "                tokens_sample.append(noun_phrases[chunk_index][0])\n",
    "                for a in range(i,noun_phrases[chunk_index][2]):\n",
    "                    token_map.append(len(tokens_sample)-1)\n",
    "                i = noun_phrases[chunk_index][2]\n",
    "                chunk_index = chunk_index+1\n",
    "        else:\n",
    "            tokens_sample.append(tokens[i][0])\n",
    "            token_map.append(len(tokens_sample)-1)\n",
    "            i = i+1\n",
    "    return tokens_sample, token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Men never were shown in a negative light\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(token.text.lower(),token.i,token.head.i, token.is_punct) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token dependency\n",
    "def token_dependency(dataset):\n",
    "    for i,sample in enumerate(dataset):\n",
    "        dataset_article = {}\n",
    "        dataset_article_a = {}\n",
    "        doc = nlp(sample[1])\n",
    "        dataset_article[\"token_caption\"] = [(token.text.lower(),token.i,token.head.i, token.is_punct) for token in doc]\n",
    "        dataset_article[\"chunk\"] =  [(chunk.text.lower(),chunk.start,chunk.end) for chunk in doc.noun_chunks]\n",
    "        token_sample,token_map = re_organize_caption(dataset_article[\"token_caption\"],dataset_article[\"chunk\"])\n",
    "        dependency = [(token_map[t[1]],token_map[t[2]]) for t in dataset_article[\"token_caption\"] if (not (token_map[t[1]]) == token_map[t[2]]) and \n",
    "                      (not t[3])]\n",
    "        \n",
    "        dataset_article_a[\"chunk_cap\"] = token_sample\n",
    "        dataset_article_a[\"token_cap\"] = [t[0] for t in dataset_article[\"token_caption\"]]\n",
    "        \n",
    "        dataset_article_a[\"token_dep\"] = [(t[1],t[2]) for t in dataset_article[\"token_caption\"] if (not t[1] == t[2]) and (not t[3]) and t[0]!=\" \" \n",
    "                                          and dataset_article[\"token_caption\"][t[2]][0]!= \" \"]\n",
    "        dataset_article_a[\"chunk_dep\"] = dependency\n",
    "        \n",
    "        dataset_article_a[\"chunk\"] = [temp[0] for temp in dataset_article[\"chunk\"]]\n",
    "        dataset_article_a[\"chunk_index\"] = [token_map[temp[1]] for temp in dataset_article[\"chunk\"]]\n",
    "        \n",
    "        dataset[i].append(dataset_article_a)\n",
    "    return dataset\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(\"text\", \"pre_train.csv\"))\n",
    "train, val = train_test_split(train_data, test_size=0.2, shuffle=True, random_state=42)\n",
    "test = pd.read_csv(os.path.join(\"text\", \"pre_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>7128</td>\n",
       "      <td>military</td>\n",
       "      <td>Texas</td>\n",
       "      <td>courageous and honest analysis of need to use ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>4688</td>\n",
       "      <td>engulfed</td>\n",
       "      <td>UNK</td>\n",
       "      <td>zachzaidman 670thescore old b a shame if that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>6984</td>\n",
       "      <td>massacre</td>\n",
       "      <td>Cottonwood Arizona</td>\n",
       "      <td>tell barackobama to rescind medals of honor gi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>4103</td>\n",
       "      <td>drought</td>\n",
       "      <td>Spokane, WA</td>\n",
       "      <td>worried about how the ca drought might affect ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>6706</td>\n",
       "      <td>lava</td>\n",
       "      <td>Medan,Indonesia</td>\n",
       "      <td>youngheroesid lava blast amp power red panther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>7470</td>\n",
       "      <td>obliteration</td>\n",
       "      <td>Merica!</td>\n",
       "      <td>eganator2000 there agent many obliteration ser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>7691</td>\n",
       "      <td>panic</td>\n",
       "      <td>UNK</td>\n",
       "      <td>just had a panic attack bc i dont have enough ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1242</td>\n",
       "      <td>blood</td>\n",
       "      <td>UNK</td>\n",
       "      <td>common hem712c automatic blood pressure monito...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>10862</td>\n",
       "      <td>unknown</td>\n",
       "      <td>UNK</td>\n",
       "      <td>officials say a quarante is in place at an ala...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>10409</td>\n",
       "      <td>whirlwind</td>\n",
       "      <td>Stamford &amp; Cork (&amp; Shropshire)</td>\n",
       "      <td>i moved to england five years ago today what a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6090 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       keyword                        location   \n",
       "4996   7128      military                           Texas  \\\n",
       "3263   4688      engulfed                             UNK   \n",
       "4907   6984      massacre              Cottonwood Arizona   \n",
       "2855   4103       drought                     Spokane, WA   \n",
       "4716   6706          lava                 Medan,Indonesia   \n",
       "...     ...           ...                             ...   \n",
       "5226   7470  obliteration                         Merica!   \n",
       "5390   7691         panic                             UNK   \n",
       "860    1242         blood                             UNK   \n",
       "7603  10862       unknown                             UNK   \n",
       "7270  10409     whirlwind  Stamford & Cork (& Shropshire)   \n",
       "\n",
       "                                                   text  target  \n",
       "4996  courageous and honest analysis of need to use ...       1  \n",
       "3263  zachzaidman 670thescore old b a shame if that ...       0  \n",
       "4907  tell barackobama to rescind medals of honor gi...       1  \n",
       "2855  worried about how the ca drought might affect ...       1  \n",
       "4716  youngheroesid lava blast amp power red panther...       0  \n",
       "...                                                 ...     ...  \n",
       "5226  eganator2000 there agent many obliteration ser...       0  \n",
       "5390  just had a panic attack bc i dont have enough ...       0  \n",
       "860   common hem712c automatic blood pressure monito...       0  \n",
       "7603  officials say a quarante is in place at an ala...       1  \n",
       "7270  i moved to england five years ago today what a...       1  \n",
       "\n",
       "[6090 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = read_json(\"./sarcasm/twitter/dataset_text/train.json\")\n",
    "valset = read_json(\"./sarcasm/twitter/dataset_text/val.json\")\n",
    "testset = read_json(\"./sarcasm/twitter/dataset_text/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dep = token_dependency(testset)\n",
    "train_dep = token_dependency(trainset)\n",
    "val_dep = token_dependency(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dep = token_dependency(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dep = token_dependency(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(\"./sarcasm/twitter/dataset_text/traindep.json\", train_dep)\n",
    "write_json(\"./sarcasm/twitter/dataset_text/valdep.json\", val_dep)\n",
    "write_json(\"./sarcasm/twitter/dataset_text/testdep.json\", test_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train的caption有一定的重复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_attr = \"./sarcasm/twitter/dataset_text/multilabel_database/img_to_five_words.txt\"\n",
    "cap_test = \"./sarcasm/twitter/dataset_text/gecaption/testcap.json\"\n",
    "cap_val = \"./sarcasm/twitter/dataset_text/gecaption/valcap.json\"\n",
    "cap_train = \"./sarcasm/twitter/dataset_text/gecaption/traincap.json\"\n",
    "train_dep = \"./sarcasm/twitter/dataset_text/traindep.json\"\n",
    "val_dep = \"./sarcasm/twitter/dataset_text/valdep.json\"\n",
    "test_dep = \"./sarcasm/twitter/dataset_text/testdep.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json(path):\n",
    "    with open(path,\"r\",encoding = 'utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "def write_json(path,data):\n",
    "    with open(path,\"w\",encoding = 'utf-8') as f:\n",
    "        json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dep = read_json(train_dep)\n",
    "val_dep = read_json(val_dep)\n",
    "test_dep = read_json(test_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_test = read_json(cap_test)\n",
    "cap_val = read_json(cap_val)\n",
    "cap_train = read_json(cap_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dep), len(val_dep), len(test_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cap_train), len(cap_val), len(cap_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attr=dict()\n",
    "file=open(\"./sarcasm/twitter/dataset_text/multilabel_database/img_to_five_words.txt\",\"rb\")\n",
    "a=0\n",
    "for line in file:\n",
    "    content=eval(line)\n",
    "    data_attr[content[0]]=content[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_txt\n",
    "file_path = \"train.txt\"\n",
    "with open(file_path,\"w\") as f:\n",
    "    for sample in train_dataset:\n",
    "        f.write(\"dataset_image/\"+sample[0]+\".jpg\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"test.txt\"\n",
    "with open(file_path,\"w\") as f:\n",
    "    for sample in test_dataset:\n",
    "        f.write(\"dataset_image/\"+sample[0]+\".jpg\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"val.txt\"\n",
    "with open(file_path,\"w\") as f:\n",
    "    for sample in val_dataset:\n",
    "        f.write(\"dataset_image/\"+sample[0]+\".jpg\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add anp\n",
    "test_anp= read_json(\"./sarcasm/twitter/dataset_text/anp/test.json\")\n",
    "val_anp= read_json(\"./sarcasm/twitter/dataset_text/anp/val.json\")\n",
    "train_anp= read_json(\"./sarcasm/twitter/dataset_text/anp/train.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_anp_set = []\n",
    "for sample in test_anp['images']:\n",
    "    anps = sample['bi-concepts']\n",
    "    test_anp_set.append([a.replace('_', \" \") for a in list(anps.keys())])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_anp_set = []\n",
    "for sample in val_anp['images']:\n",
    "    anps = sample['bi-concepts']\n",
    "    val_anp_set.append([a.replace('_', \" \") for a in list(anps.keys())])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_anp_set = []\n",
    "for sample in train_anp['images']:\n",
    "    anps = sample['bi-concepts']\n",
    "    train_anp_set.append([a.replace('_', \" \") for a in list(anps.keys())])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_anp_set), len(val_anp_set), len(test_anp_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for i, sample in enumerate(train_dep):\n",
    "    id_attr = sample[0]\n",
    "    sample.append(cap_train[20:][i])\n",
    "    attr = data_attr[id_attr]\n",
    "    sample.append(attr)\n",
    "    sample.append(train_anp_set[i])\n",
    "    train_dataset.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = []\n",
    "for i, sample in enumerate(val_dep):\n",
    "    id_attr = sample[0]\n",
    "    sample.append(cap_val[i])\n",
    "    attr = data_attr[id_attr]\n",
    "    sample.append(attr)\n",
    "    sample.append(val_anp_set[i])\n",
    "    val_dataset.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = []\n",
    "for i, sample in enumerate(test_dep):\n",
    "    id_attr = sample[0]\n",
    "    sample.append(cap_test[i])\n",
    "    attr = data_attr[id_attr]\n",
    "    sample.append(attr)\n",
    "    sample.append(test_anp_set[i])\n",
    "    test_dataset.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(\"./sarcasm/twitter/dataset_text/trainknow.json\", train_dataset)\n",
    "write_json(\"./twitter/dataset_text/valknow.json\", val_dataset)\n",
    "write_json(\"./sarcasm/twitter/dataset_text/testknow.json\", test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_json(\"./sarcasm/twitter/dataset_text/trainknow.json\")\n",
    "val = read_json(\"./sarcasm/twitter/dataset_text/valknow.json\")\n",
    "test = read_json(\"./sarcasm/twitter/dataset_text/testknow.json\")\n",
    "# *."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sample in enumerate(val):\n",
    "    print (i, sample[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(test_dataset[0][-1], list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "def re_organize_caption(tokens,noun_phrases):\n",
    "    # tokens_smaple token+np\n",
    "    # token_map token_map[a] a 是\n",
    "    tokens_sample = []\n",
    "    chunk_index = 0\n",
    "    chunk_len = len(noun_phrases)\n",
    "    i = 0\n",
    "    token_map = []\n",
    "    while (i<len(tokens)):\n",
    "        if chunk_index<chunk_len:\n",
    "            if i<noun_phrases[chunk_index][1]:\n",
    "                tokens_sample.append(tokens[i][0])\n",
    "                token_map.append(len(tokens_sample)-1)\n",
    "                i = i+1\n",
    "            else:\n",
    "                tokens_sample.append(noun_phrases[chunk_index][0])\n",
    "                for a in range(i,noun_phrases[chunk_index][2]):\n",
    "                    token_map.append(len(tokens_sample)-1)\n",
    "                i = noun_phrases[chunk_index][2]\n",
    "                chunk_index = chunk_index+1\n",
    "        else:\n",
    "            tokens_sample.append(tokens[i][0])\n",
    "            token_map.append(len(tokens_sample)-1)\n",
    "            i = i+1\n",
    "    return tokens_sample, token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token dependency\n",
    "def token_dependency(dataset):\n",
    "    for i,sample in enumerate(dataset):\n",
    "        dataset_article = {}\n",
    "        dataset_article_a = {}\n",
    "        # the caption index is -3 \n",
    "        doc = nlp(sample[-3].strip())\n",
    "        dataset_article[\"token_caption\"] = [(token.text.lower(),token.i,token.head.i, token.is_punct) for token in doc]\n",
    "        dataset_article[\"chunk\"] =  [(chunk.text.lower(),chunk.start,chunk.end) for chunk in doc.noun_chunks]\n",
    "        token_sample,token_map = re_organize_caption(dataset_article[\"token_caption\"],dataset_article[\"chunk\"])\n",
    "        dependency = [(token_map[t[1]],token_map[t[2]]) for t in dataset_article[\"token_caption\"] if (not (token_map[t[1]]) == token_map[t[2]]) and \n",
    "                      (not t[3])]\n",
    "        \n",
    "        dataset_article_a[\"token_cap\"] = [t[0] for t in dataset_article[\"token_caption\"]]\n",
    "        \n",
    "        dataset_article_a[\"token_dep\"] = [(t[1],t[2]) for t in dataset_article[\"token_caption\"] if (not t[1] == t[2]) and (not t[3]) and t[0]!=\" \" \n",
    "                                          and dataset_article[\"token_caption\"][t[2]][0]!= \" \"]\n",
    "        \n",
    "        dataset[i].append(dataset_article_a)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dep = token_dependency(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dep = token_dependency(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dep = token_dependency(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_json(\"./sarcasm/twitter/dataset_text/trainknow_dep.json\", train_dep)\n",
    "write_json(\"./sarcasm/twitter/dataset_text/valknow_dep.json\", val_dep)\n",
    "# write_json(\"./sarcasm/twitter/dataset_text/testknow_dep.json\", test_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dep = read_json(\"./sarcasm/twitter/dataset_text/trainknow_dep.json\")\n",
    "val_dep = read_json(\"./sarcasm/twitter/dataset_text/valknow_dep.json\")\n",
    "# test_dep = read_json(\"./sarcasm/twitter/dataset_text/testknow_dep.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "for smaple in val_dep:\n",
    "    length.append(len(smaple[-1]['token_dep'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['I', 'love', 'you'],['data', 'is', 'love'],['[CLS]','thank', 'you']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cap=tokenizer(data, is_split_into_words=True, return_tensors='pt', truncation=True, max_length=100, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,  146, 1567, 1128,  102],\n",
       "        [ 101, 2233, 1110, 1567,  102],\n",
       "        [ 101,  101, 6243, 1128,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert_model = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_spans = []\n",
    "word_len = []\n",
    "token_lens=[len(i) for i in data]\n",
    "for index_encode, len_token in enumerate(token_lens): # index_encode是第i个样本 len_token是第i条语句的长度\n",
    "    word_span_ = []\n",
    "    for i in range(len_token):\n",
    "        word_span = encoded_cap[index_encode].word_to_tokens(i)\n",
    "        if word_span is not None:\n",
    "            # delete [CLS]\n",
    "            word_span_.append([word_span[0] - 1, word_span[1] - 1])\n",
    "    word_spans.append(word_span_)\n",
    "    word_len.append(len(word_span_))\n",
    "\n",
    "max_len1 = max(word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(token_lens[2]):\n",
    "    if encoded_cap[2].word_to_tokens(i) is None:\n",
    "        print('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 2]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\cmcr\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\cmcr\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\email/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a1cd196ad340e1848aa6cd9afbf9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/30.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 7, 7])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([128, 64, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([96])\n",
      "torch.Size([96])\n",
      "torch.Size([128, 96, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([128, 160, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([192])\n",
      "torch.Size([192])\n",
      "torch.Size([128, 192, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([224])\n",
      "torch.Size([224])\n",
      "torch.Size([128, 224, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 128, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([160])\n",
      "torch.Size([160])\n",
      "torch.Size([128, 160, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([192])\n",
      "torch.Size([192])\n",
      "torch.Size([128, 192, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([224])\n",
      "torch.Size([224])\n",
      "torch.Size([128, 224, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([288])\n",
      "torch.Size([288])\n",
      "torch.Size([128, 288, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([128, 320, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([352])\n",
      "torch.Size([352])\n",
      "torch.Size([128, 352, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([384])\n",
      "torch.Size([384])\n",
      "torch.Size([128, 384, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([416])\n",
      "torch.Size([416])\n",
      "torch.Size([128, 416, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([448])\n",
      "torch.Size([448])\n",
      "torch.Size([128, 448, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([480])\n",
      "torch.Size([480])\n",
      "torch.Size([128, 480, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([288])\n",
      "torch.Size([288])\n",
      "torch.Size([128, 288, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([320])\n",
      "torch.Size([320])\n",
      "torch.Size([128, 320, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([352])\n",
      "torch.Size([352])\n",
      "torch.Size([128, 352, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([384])\n",
      "torch.Size([384])\n",
      "torch.Size([128, 384, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([416])\n",
      "torch.Size([416])\n",
      "torch.Size([128, 416, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([448])\n",
      "torch.Size([448])\n",
      "torch.Size([128, 448, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([480])\n",
      "torch.Size([480])\n",
      "torch.Size([128, 480, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([544])\n",
      "torch.Size([544])\n",
      "torch.Size([128, 544, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([576])\n",
      "torch.Size([576])\n",
      "torch.Size([128, 576, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([608])\n",
      "torch.Size([608])\n",
      "torch.Size([128, 608, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 640, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([672])\n",
      "torch.Size([672])\n",
      "torch.Size([128, 672, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([704])\n",
      "torch.Size([704])\n",
      "torch.Size([128, 704, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([736])\n",
      "torch.Size([736])\n",
      "torch.Size([128, 736, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([128, 768, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([800])\n",
      "torch.Size([800])\n",
      "torch.Size([128, 800, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([832])\n",
      "torch.Size([832])\n",
      "torch.Size([128, 832, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([864])\n",
      "torch.Size([864])\n",
      "torch.Size([128, 864, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([896])\n",
      "torch.Size([896])\n",
      "torch.Size([128, 896, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([928])\n",
      "torch.Size([928])\n",
      "torch.Size([128, 928, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([960])\n",
      "torch.Size([960])\n",
      "torch.Size([128, 960, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([992])\n",
      "torch.Size([992])\n",
      "torch.Size([128, 992, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([544])\n",
      "torch.Size([544])\n",
      "torch.Size([128, 544, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([576])\n",
      "torch.Size([576])\n",
      "torch.Size([128, 576, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([608])\n",
      "torch.Size([608])\n",
      "torch.Size([128, 608, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([640])\n",
      "torch.Size([640])\n",
      "torch.Size([128, 640, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([672])\n",
      "torch.Size([672])\n",
      "torch.Size([128, 672, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([704])\n",
      "torch.Size([704])\n",
      "torch.Size([128, 704, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([736])\n",
      "torch.Size([736])\n",
      "torch.Size([128, 736, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n",
      "torch.Size([128, 768, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([800])\n",
      "torch.Size([800])\n",
      "torch.Size([128, 800, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([832])\n",
      "torch.Size([832])\n",
      "torch.Size([128, 832, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([864])\n",
      "torch.Size([864])\n",
      "torch.Size([128, 864, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([896])\n",
      "torch.Size([896])\n",
      "torch.Size([128, 896, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([928])\n",
      "torch.Size([928])\n",
      "torch.Size([128, 928, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([960])\n",
      "torch.Size([960])\n",
      "torch.Size([128, 960, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([992])\n",
      "torch.Size([992])\n",
      "torch.Size([128, 992, 1, 1])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([32, 128, 3, 3])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "torch.Size([1000, 1024])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "for para in model.parameters():\n",
    "    print(para.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTMnn = torch.nn.LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'st'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\同步文件夹\\BaiduSyncdisk\\验证代码\\kaggle_NLP_competition\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(\"text\", \"pre_train.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4996    1\n",
       "3263    0\n",
       "4907    1\n",
       "2855    1\n",
       "4716    0\n",
       "       ..\n",
       "5226    0\n",
       "5390    0\n",
       "860     0\n",
       "7603    1\n",
       "7270    1\n",
       "Name: target, Length: 6090, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644    so you have a new weapon that can cause unimag...\n",
       "2227    the camping things i do for gishwhes just got ...\n",
       "5448    it georgegalloway it galloway4mayor the col p...\n",
       "132     aftershock back to school kick off was great i...\n",
       "6845    in response to trauma children of admits devel...\n",
       "                              ...                        \n",
       "1835                smusx16475 type just crashed You host\n",
       "506     christian attacked by muslin at the temple mou...\n",
       "3592    man charged over fatal crash near bubo refused...\n",
       "6740    usnwsgov severe weather statement issued augus...\n",
       "1634    great british ltbgtbakeltbgt off back and forg...\n",
       "Name: text, Length: 1523, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmcr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
